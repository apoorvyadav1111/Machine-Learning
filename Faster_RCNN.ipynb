{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Faster RCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1zRy_uBL2X9lHHlRMBT3XSFX6GdWw9q7H",
      "authorship_tag": "ABX9TyPO8Ad/I87s4JGR4i9XjrPn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apoorvyadav1111/Machine-Learning-keras/blob/master/Faster_RCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQP37q054KMG",
        "colab_type": "code",
        "outputId": "f8b01210-2a06-42f0-df78-62dd9e8eb2ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "%tensorflow_version 1.14\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "import random\n",
        "import sys\n",
        "import time\n",
        "import pprint\n",
        "import numpy as np\n",
        "from optparse import OptionParser\n",
        "import pickle\n",
        "import math\n",
        "import cv2\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.metrics import average_precision_score\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "from keras.layers import Flatten,Dense,Input,Conv2D,MaxPool2D,Dropout\n",
        "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, TimeDistributed\n",
        "from keras.engine.topology import get_source_inputs\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.objectives import categorical_crossentropy\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.utils import generic_utils\n",
        "from keras.engine import Layer,InputSpec\n",
        "from keras import initializers, regularizers\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.14`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20t7LLyj7698",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config:\n",
        "\n",
        "\n",
        "  def __init__(self):\n",
        "    self.verbose = True\n",
        "\n",
        "    self.network = 'vgg'\n",
        "\n",
        "    self.use_horizontal_flips = False\n",
        "    self.use_vertical_flips = False\n",
        "    self.rot_90 = False\n",
        "\n",
        "    self.anchor_box_scales = [64,128,256]\n",
        "    self.anchor_box_ratios = [[1,1],\n",
        "                              [1./math.sqrt(2),2./math.sqrt(2)],\n",
        "                              [2./math.sqrt(2),1./math.sqrt(2)]]\n",
        "    self.im_size = 300\n",
        "\n",
        "    self.img_channel_mean = [103.939,166.779,123.68]\n",
        "    self.img_scaling_factor = 1.0\n",
        "\n",
        "    self.num_rois = 4\n",
        "    self.rpn_stride = 16\n",
        "\n",
        "    self.std_scaling = 4.0\n",
        "    self.classifier_regr_std = [8.0,8.0,4.0,4.0]\n",
        "\n",
        "    self.rpn_min_overlap = 0.3\n",
        "    self.rpn_max_overlap = 0.7\n",
        "\n",
        "    self.classifier_min_overlap = 0.1\n",
        "    self.classifier_max_overlap = 0.5\n",
        "\n",
        "    self.class_mapping = None\n",
        "    self.model_path = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z98GIKSC_7ZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(input_path):\n",
        "\n",
        "  found_bg = False\n",
        "  all_imgs = {}\n",
        "\n",
        "  classes_count = {}\n",
        "  class_mapping = {}\n",
        "\n",
        "  visualize = True\n",
        "\n",
        "  i = 1\n",
        "\n",
        "  with open(input_path,'r') as f:\n",
        "    print('Parsing annotation files....')\n",
        "\n",
        "    for line in f:\n",
        "\n",
        "      sys.stdout.write('\\r'+'idx='+str(i))\n",
        "      i+=1\n",
        "\n",
        "      line_split = line.strip().split(',')\n",
        "\n",
        "      fname,x1,x2,y1,y2,class_name = line_split\n",
        "\n",
        "      if class_name not in classes_count:\n",
        "        classes_count[class_name] = 1\n",
        "      else:\n",
        "        classes_count[class_name] += 1\n",
        "      \n",
        "      if class_name not in class_mapping:\n",
        "        if class_name == 'bg' and found_bg == False:\n",
        "          print('Found class name with special name bg. Will be treated as a background region (this is usually for hard negative mining).')\n",
        "          found_bg = True\n",
        "        class_mapping[class_name] = len(class_mapping)\n",
        "      \n",
        "      if fname not in all_imgs:\n",
        "        all_imgs[fname] = {}\n",
        "\n",
        "        img = cv2.imread(fname)\n",
        "        r,c = img.shape[0:2]\n",
        "        all_imgs[fname]['filepath'] = fname\n",
        "        all_imgs[fname]['width'] = c\n",
        "        all_imgs[fname]['height'] = r\n",
        "        all_imgs[fname]['bboxes'] = []\n",
        "      \n",
        "      all_imgs[fname]['bboxes'].append({\n",
        "          'class':class_name,\n",
        "          'x1':int(x1),\n",
        "          'x2':int(x2),\n",
        "          'y1':int(y1),\n",
        "          'y2':int(y2)\n",
        "      })\n",
        "    \n",
        "    all_data = []\n",
        "    for key in all_imgs:\n",
        "      all_data.append(all_imgs[key])\n",
        "\n",
        "    if found_bg:\n",
        "      if class_mapping['bg'] != len(class_mapping) - 1:\n",
        "        key_to_switch = [key for key in class_mapping.keys() if class_mapping[key] == len(class_mapping)-1][0]\n",
        "        val_to_switch = class_mapping['bg'] \n",
        "        class_mapping[key_to_switch] = val_to_switch\n",
        "\n",
        "    return all_data, classes_count, class_mapping "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRbMg5ITFNKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RoiPoolingConv(Layer):\n",
        "  \n",
        "  def __init__(self,pool_size,num_rois, **kwargs):\n",
        "\n",
        "    self.dim_ordering = K.image_dim_ordering()\n",
        "    self.pool_size = pool_size\n",
        "    self.num_rois = num_rois\n",
        "\n",
        "    super(RoiPoolingConv,self).__init__(**kwargs)\n",
        "  \n",
        "  def build(self,input_shape):\n",
        "    self.nb_channels = input_shape[0][3]\n",
        "  \n",
        "  def compute_output_shape(self,input_shape):\n",
        "    return None,self,num_rois,self,pool_size,self.nb_channels\n",
        "\n",
        "  def call(self,x,mask=None):\n",
        "    assert(len(x)==2)\n",
        "    img = x[0]\n",
        "    rois = x[1]\n",
        "\n",
        "    input_shape = K.shape(img)\n",
        "\n",
        "    outputs = []\n",
        "\n",
        "    for roi_idx in range(self.num_rois):\n",
        "      x = rois[0,roi_idx,0]\n",
        "      y = rois[0,roi_idx,1]\n",
        "      w = rois[0,roi_idx,2]\n",
        "      h = rois[0,roi_idx,3]\n",
        "\n",
        "      x = K.cast(x,'int32')\n",
        "      y = K.cast(y,'int32')\n",
        "      w = K.cast(w,'int32')\n",
        "      h = K.cast(h,'int32')\n",
        "\n",
        "      rs = tf.image.resize(img[:,y:y+h,x:x+w,:],(self.pool_size,self.pool_size))\n",
        "      output.append(rs)\n",
        "    final_output = K.concatenate(outputs,axis = 0)\n",
        "\n",
        "    final_output = K.reshape(final_output,(1,self.num_rois,self.pool_size,self.pool_size,self,nb_channels))\n",
        "\n",
        "    final_output = K.permute_dimensions(final_output,(0,1,2,3,4))\n",
        "\n",
        "    return final_output\n",
        "  \n",
        "  def get_config(self):\n",
        "    config = {'pool_size':self.pool_size,\n",
        "              'num_rois':self.num_rois}\n",
        "    base_config = super(RoiPoolingConv,self).get_config()\n",
        "\n",
        "    return dict(list(base_config.items())+list(config.items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_EqkbYZzQVq",
        "colab_type": "text"
      },
      "source": [
        "VGG Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4CfAHtGwMyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_image_output_length(w,h):\n",
        "  def get_output_length(inp_l):\n",
        "    return inp_l//16\n",
        "  return get_output_length(w),get_output_length(h)\n",
        "\n",
        "def nn_base(input_tensor = None,trainable=False):\n",
        "\n",
        "  input_shape = (None,None,3)\n",
        "\n",
        "  if input_tensor is None:\n",
        "    img_input = Input(shape=input_shape)\n",
        "  else:\n",
        "    if not K.is_keras_tensor(input_tensor):\n",
        "      img_input = Input(tensor=input_tensor,shape=input_shape)\n",
        "    else:\n",
        "      imp_input = input_tensor\n",
        "  bn_axis = 3\n",
        "  #Block 1\n",
        "  x = Conv2D(64,(3,3),activation='relu',padding='same',name='block1_conv1')(img_input)\n",
        "  x = Conv2D(64,(3,3),activation='relu',padding='same',name='block1_conv2')(x)\n",
        "  x = MaxPool2D((2,2),strides=(2,2),name='block1_pool')(x)\n",
        "\n",
        "  #Block 2\n",
        "  x = Conv2D(128,(3,3),activation='relu',padding='same',name='block2_conv1')(x)\n",
        "  x = Conv2D(128,(3,3),activation='relu',padding='same',name='block2_conv2')(x)\n",
        "  x = MaxPool2D((2,2),strides=(2,2),name='block2_pool')(x)\n",
        "\n",
        "  #Block 3\n",
        "  x = Conv2D(256,(3,3),activation='relu',padding='same',name='block3_conv1')(x)\n",
        "  x = Conv2D(256,(3,3),activation='relu',padding='same',name='block3_conv2')(x)\n",
        "  x = Conv2D(256,(3,3),activation='relu',padding='same',name='block3_conv3')(x)\n",
        "  x = MaxPooling2D((2,2),strides=(2,2),name='block3_pool')(x)\n",
        "\n",
        "  #Block 4\n",
        "  x = Conv2D(512,(3,3),activation='relu',padding='same',name='block4_conv1')(x)\n",
        "  x = Conv2D(512,(3,3),activation='relu',padding='same',name='block4_conv2')(x)\n",
        "  x = Conv2D(512,(3,3),activation='relu',padding='same',name='block4_conv3')(x)\n",
        "  x = MaxPooling2D((2,2),strides=(2,2),name='block4_pool')(x)\n",
        "\n",
        "  #Block 5\n",
        "  x = Conv2D(512,(3,3),activation='relu',padding='same',name='block5_conv1')(x)\n",
        "  x = Conv2D(512,(3,3),activation='relu',padding='same',name='block5_conv2')(x)\n",
        "  x = Conv2D(512,(3,3),activation='relu',padding='same',name='block5_conv3')(x)\n",
        "# x = Maxpooling2D((2,2),strides=(2,2),name='block5_pool)(x)\n",
        "\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdbUs71LOJ1m",
        "colab_type": "text"
      },
      "source": [
        "RPN Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMKjfj913nVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rpn_layer(base_layers,num_anchors):\n",
        "  x = Conv2D(512,\n",
        "             (3,3),\n",
        "             activation='relu',\n",
        "             padding='same',\n",
        "             kernal_initializer='normal',\n",
        "             name = 'rpn_conv1'\n",
        "             )(base_layers)\n",
        "  x_class = Conv2D(num_anchors,\n",
        "                   (1,1),\n",
        "                   activation='sigmoid',\n",
        "                   kernal_initializer='uniform',\n",
        "                   name = 'rpn_out_class'\n",
        "                   )(x)\n",
        "  x_regr = Conv2D(num_anchors*4,\n",
        "                  (1,1),\n",
        "                  activation='linear',\n",
        "                  kernal_initializer='zero',\n",
        "                  name='rpn_out_regress')(x)\n",
        "  return [x_class,x_regr,base_layers]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81KjxUgwRqk-",
        "colab_type": "text"
      },
      "source": [
        "Classifier Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_67hmKsrRnaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classifier_layer(base_layers,input_rois,num_rois,nb_classes=4):\n",
        "  input_shape = (num_rois,7,7,512)\n",
        "\n",
        "  pooling_regions = 7\n",
        "\n",
        "  out_roi_pool = RoiPoolingConv(pooling_regions, num_rois)([base_layers,input_rois])\n",
        "\n",
        "  out = TimeDistributed(Flatten(name='flatten'))(out_roi_pool)\n",
        "  out = TimeDistributed(Dense(4096,activation='relu',name='fc1'))\n",
        "  out = TimeDistributed(Dropout(0.5))(out)\n",
        "  out = TimeDistributed(Dense(4096,activation='relu',name='fc2'))\n",
        "  out = TimeDistributed(Dropout(0.5))(out)\n",
        "\n",
        "  out_class = TimeDistributed(Dense(nb_classes,\n",
        "                              activation='softmax',\n",
        "                              kernel_initializer='zero'),name = 'dense_class_{}'.format(nb_classes))(out)\n",
        "  \n",
        "  out_regr = TimeDistributed(Dense((4*nb_classes-1),\n",
        "                             activation='linear',\n",
        "                             kernel_initializer='zero'),\n",
        "                             name='dense_regress_{}'.format(nb_classes))(out)\n",
        "  return [out_class,out_regr]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7_5EqlkVKGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def union(au,bu,intersection):\n",
        "  area_a = (au[2] - au[0])*(a[3]-au[1])\n",
        "  area_b = (bu[2] - bu[0])*(bu[3]-bu[1])\n",
        "  area_union = area_a + area_b - intersection\n",
        "def intersection(ai,bi):\n",
        "  x = max(ai[0],bi[0])\n",
        "  y = max(ai[1],ai[1])\n",
        "  w = min(ai[2],bi[2])\n",
        "  h = min(ai[3],bi[3])\n",
        "\n",
        "  if w<0 and h<0:\n",
        "    return 0\n",
        "  return w*h\n",
        "\n",
        "def iou(a,b):\n",
        "  if a[0] >=  a[2] or a[1]>=a[3] or b[0] >= b[2] or b[1] >= b[3]:\n",
        "    return 0\n",
        "  inter = intersection(a,b)\n",
        "  uni = union(a,b,inter)\n",
        "\n",
        "  return float(inter)/float(uni+ 1e-6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGI9hPAmyHbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_rpn(C,img_data, w,h,re_w,re_h,img_len_calc_func):\n",
        "  downscale = float(C.rpn_stride)\n",
        "  anchor_sizes = C.anchor_box_scales\n",
        "  anchor_ratios = C.anchor_box_ratios\n",
        "\n",
        "  num_anchors = len(anchor_sizes)*len(anchor_ratios)\n",
        "\n",
        "  (out_w,out_h) = img_len_calc_func(re_w,re_h)\n",
        "\n",
        "  n_anchratios = len(anchor_ratios)\n",
        "\n",
        "  y_rpn_overlap = np.zeros((out_h,out_w,num_anchors))\n",
        "  y_is_box_valid = np.zeros((out_h,out_w,num_anchors))\n",
        "  y_rpn_regr = np.zeros((out_h,out_w,num_anchors))\n",
        "\n",
        "  num_bboxes = len(img_data['bboxes'])\n",
        "\n",
        "  num_anchors_for_bboxes = np.zeros(num_bboxes).astype(int)\n",
        "  best_anchor_for_bbox = -1*np.ones((num_bboxes,4)).astype(int)\n",
        "  best_iou_for_bbox = np.zeros(num_bboxes).astype(np.float32)\n",
        "  best_x_for_bbox = np.zeros((num_bboxes,4)).astype(int)\n",
        "  best_dx_for_bbox = np.zeros((num_bboxes,4)).astype(np.float32)\n",
        "\n",
        "  gta =  np.zeros((num_bboxes,4))\n",
        "  for bbox_num,bbox in enumerate(img_data['bboxes']):\n",
        "    gta[bbox_num,0] = bbox['x1'] * (re_w/float(w))\n",
        "    gta[bbox_num,1] = bbox['x2'] * (re_w/float(w))\n",
        "    gta[bbox_num,2] = bbox['y1'] * (re_h/float(h))\n",
        "    gta[bbox_num,3] = bbox['y2'] * (re_h/float(h))\n",
        "  \n",
        "  for anchor_size_idx in range(len(anchor_sizes)):\n",
        "    for anchor_ratio_idx in range(n_anchratios):\n",
        "      anchor_x = anchor_sizes[anchor_size_idx]*anchor_ratios[anchor_ratio_idx][0]\n",
        "      anchor_y = anchor_sizes[anchor_size_idx]*anchor_ratios[anchor_ratio_idx][1]\n",
        "\n",
        "      for ix in range(out_w):\n",
        "\n",
        "        x1_anc = downscale*(ix+0.5) - anchor_x/2\n",
        "        x2_anc = downscale*(ix+0.5) - anchor_x/2\n",
        "\n",
        "        if x1_anc < 0 or x2_anc>re_w:\n",
        "          continue\n",
        "        for jy in range(out_h):\n",
        "\n",
        "          y1_anc = downscale*(jy+0.5) - anchor_y/2\n",
        "          y2_anc = downscale*(jy+0.5) - anchor_y/2\n",
        "\n",
        "          if y1_anc <0  or y2_anc>re_h:\n",
        "            continue\n",
        "          \n",
        "          bbox_type = 'neg'\n",
        "\n",
        "          best_iou_for_loc = 0.0\n",
        "\n",
        "          for bbox_num in range(num_bboxes):\n",
        "            a = [gta[bbox_num,0],gta[bbox_num,1],gta[bbox_num,2],gta[bbox_num,3]]\n",
        "            b = [x1_anc,x2_anc,y1_anc,y2_anc]\n",
        "            curr_iou = iou(a,b)\n",
        "            if curr_iou > best_iou_for_bbox[bbox_num] or curr_iou > C.rpn_max_overlap :\n",
        "              cx = (gta[bbox_num,0] + gta[bbox_num,1])/2.0\n",
        "              cy = (gta[bbox_num,2] + gta[bbox_num,3])/2.0\n",
        "\n",
        "              cxa = (x1_anc + x2_anc) /2.0\n",
        "              cya = (y1_anc + y2_anc) /2.0\n",
        "\n",
        "              tx = (cx - cxa)\n",
        "              ty = (cy - cya)\n",
        "              tw = np.log((gta[bbox_num,1]-gta[bbox_num,0])/(x2_anc-x1_anc))\n",
        "              th = np.log((gta[bbox_num,3]-gta[bbox_num,2])/(y2_anc-y1_anc))\n",
        "            \n",
        "            if img_data['bboxes'][bbox_num]['class'] != 'bg' :\n",
        "              if curr_iou>best_iou_for_bbox[bbox_num]:\n",
        "                best_anchor_for_bbox[bbox_num] = [jy,ix,anchor_ratio_idx,anchor_size_idx]\n",
        "\n",
        "                best_iou_for_bbox[bbox_num] = curr_iou\n",
        "\n",
        "                best_x_for_bbox[bbox_num,:] = [x1_anc,x2_anc,y1_anc,y2_anc]\n",
        "\n",
        "                best_dx_for_bbox[bbox_num,:] = [tx,ty,tw,th]\n",
        "\n",
        "              if curr_iou > C.rpn_max_overlap :\n",
        "                bbox_type = 'pos'\n",
        "                num_anchors_for_bboxes[bbox_num] += 1\n",
        "              \n",
        "                if curr_iou > best_iou_for_loc:\n",
        "                  best_io_for_loc = curr_iou\n",
        "                  best_regr = (tx,ty,tw,th)\n",
        "              if C.rpn_min_overlap < curr_iou < C.rpn_max_overlap:\n",
        "                if bbox_type != 'pos':\n",
        "                  bbox_type = 'neutral'\n",
        "\n",
        "          if bbox_type == 'neg':\n",
        "            y_is_box_valid[jy,ix,anchor_ratio_idx + n_anchratios * anchor_size_idx] = 1\n",
        "            y_rpn_overlap[jy,ix,anchor_ratio_idx + n_anchratios * anchor_size_idx] = 0\n",
        "          \n",
        "          elif bbox_type == 'neutral':\n",
        "            y_is_box_valid[jy,ix,anchor_ratio_idx + n_anchratios * anchor_size_idx] = 0\n",
        "            y_rpn_overlap[jy,ix,anchor_ratio_idx + n_anchratios * anchor_size_idx] = 0\n",
        "          elif bbox_type == 'pos':\n",
        "            y_is_box_valid[jy,ix,anchor_ratio_idx + n_anchratios * anchor_size_idx] = 1\n",
        "            y_rpn_overlap[jy,ix,anchor_ratio_idx + n_anchratios * anchor_size_idx] = 1\n",
        "\n",
        "            start = 4*(anchor_ratio_idx + n_anchratios*anchor_size_idx)\n",
        "            y_rpn_regr[jy,ix,start:start+4] = best_regr\n",
        "  \n",
        "  for idx in range(num_anchors_for_bboxes.shape[0]):\n",
        "    if num_anchors_for_bboxes[idx] == 0:\n",
        "      if best_anchor_for_bbox[idx,0] == -1:\n",
        "        continue\n",
        "      y_is_box_valid[\n",
        "                     best_anchor_for_bbox[idx,0],\n",
        "                     best_anchor_for_bbox[idx,1],\n",
        "                     best_anchor_for_bbox[idx,2]+n_anchratios*best_anchor_for_bbox[idx,3]\n",
        "      ] = 1\n",
        "      y_rpn_overlap[\n",
        "                    best_anchor_for_bbox[idx,0],\n",
        "                    best_anchor_for_bbox[idx,1],\n",
        "                    best_anchor_for_bbox[idx,2]+n_anchratios*best_anchor_for_bbox[idx,3]\n",
        "      ] = 1\n",
        "\n",
        "      start = 4*(best_anchor_for_bbox[idx,2] + n_anchratios*best_anchor_for_bbox[idx,3])\n",
        "\n",
        "      y_rpn_regr[\n",
        "                 best_anchor_for_bbox[idx,0],\n",
        "                 best_anchor_for_bbox[idx,1],\n",
        "                 start:start+4\n",
        "      ] = best_dx_for_bbox[idx,:]\n",
        "      \n",
        "      y_rpn_overlap = np.transpose(y_rpn_overlap,(2,0,1))\n",
        "      y_rpn_overlap = np.expand_dims(y_rpn_overlap,axis = 0)\n",
        "\n",
        "      y_is_box_valid = np.transpose(y_is_box_valid,(2,0,1))\n",
        "      y_is_box_valid = np.expand_dims(y_is_box_valid,axis=0)\n",
        "\n",
        "      y_rpn_regr = np.transpose(y_rpn_regr,(2,0,1))\n",
        "      y_rpn_regr = np.expand_dims(y_rpn_regr,axis=0)\n",
        "\n",
        "      num_pos = len(pos_locs[0])\n",
        "\n",
        "      num_regions = 256\n",
        "      if num_pos > num_regions/2:\n",
        "        val_locs = random.sample(range(num_pos),pos_locs[0] - num_regions/2)\n",
        "        y_is_box_valid[0,pos_locs[0][val_locs],pos_locs[1][val_locs],pos_locs[2][val_locs]] = 0\n",
        "        num_pos = num_regions/2\n",
        "      if len(neg_locs[0]) + num_pos > num_regions:\n",
        "        val_locs = random.sample(range(len(neg_locs[0])),len(neg_locs[0])-num_pos)\n",
        "        y_is_box_valid[0,neg_locs[0][val_locs],neg_locs[1][val_locs],neg_locs[2][val_locs]] = 0\n",
        "      \n",
        "      y_rpn_cls = np.concatenate([y_is_box_valid,y_rpn_overlap],\n",
        "                                 axis = 1)\n",
        "      y_rpn_regr = np.concatenate([np.repeat(y_rpn_overlap,4,axis=1),y_rpn_regr],\n",
        "                                  axis=1)\n",
        "      \n",
        "      return np.copy(y_rpn_cls),np.copy(y_rpn_regr), num_pos\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9O3iLbaUTZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_new_img_size(w,h,img_min_size = 300):\n",
        "  if w<=h:\n",
        "    f = float(img_min_size)/w\n",
        "    re_h = int(f*h)\n",
        "    re_w = img_min_size\n",
        "  else:\n",
        "    f = float(img_min_size)/h\n",
        "    re_w = int(f*w)\n",
        "    re_h = img_min_size\n",
        "  return re_w,re_h\n",
        "\n",
        "def augment(img_data,config,augment=True):\n",
        "  assert 'filepath' in img_data\n",
        "  assert 'bboxes' in img_data\n",
        "  assert 'width' in img_data\n",
        "  assert 'height' in img_data\n",
        "\n",
        "  img_data_aug = copy.deepcopy(img_data)\n",
        "\n",
        "  img = cv2.imread(img_data_aug['filepath'])\n",
        "\n",
        "  if augment:\n",
        "    rows,cols = img.shape[:2]\n",
        "\n",
        "    if config.use_horizontal_flips and np.random.randint(0,2) == 0:\n",
        "      img = cv2.flip(img,1)\n",
        "      for bbox in img_data_aug['bboxes']:\n",
        "        x1 = bbox['x1']\n",
        "        x2 = bbox['x2']\n",
        "        bbox['x2'] = cols-x1\n",
        "        bbox['x1'] = cols-x2\n",
        "      \n",
        "    if config.use_vertical_flips and np.random.randint(0,3) == 0:\n",
        "      img = cv2.flip(img,2)\n",
        "      for bbox in img_data_aug['bboxes']:\n",
        "        y1 = bbox['y1']\n",
        "        y2 = bbox['y2']\n",
        "        bbox['y2'] = rows - y1\n",
        "        bbox['y1'] = rows - y2\n",
        "    if config.rot_90:\n",
        "      angle = np.random.choice([0,90,180,270],1)[0]\n",
        "      if angle == 270:\n",
        "        img = np.transpose(img,(1,0,2))\n",
        "        img = cv2.flip(img,0)\n",
        "      elif angle == 180:\n",
        "        img = cv2.flip(img,-1)\n",
        "      elif angle == 90:\n",
        "        img = np.transpose(img,(1,0,2))\n",
        "        img = cv2.flip(img,1)\n",
        "      elif angle == 0:\n",
        "        pass\n",
        "      \n",
        "      for bbox in img_data_aug['bboxes']:\n",
        "        x1 = bbox['x1']\n",
        "        x2 = bbox['x2']\n",
        "        y1 = bbox['y1']\n",
        "        y2 = bbox['y2']\n",
        "\n",
        "        if angle == 270:\n",
        "          bbox['x1'] = y1\n",
        "          bbox['x2'] = y2\n",
        "          bbox['y1'] = cols - x2\n",
        "          bbox['y2'] = cols - x1\n",
        "        elif angle == 180:\n",
        "          bbox['x1'] = cols - x2\n",
        "          bbox['x2'] = cols - x1\n",
        "          bbox['y1'] = rows - y2\n",
        "          bbox['y2'] = rows - y1\n",
        "        elif angle == 90:\n",
        "          bbox['x1'] = rows - y2\n",
        "          bbox['x2'] = rows - y1\n",
        "          bbox['y1'] = x1\n",
        "          bbox['y2'] = x2\n",
        "        elif angle == 0:\n",
        "          pass\n",
        "  img_data_aug['width'] = img.shape[1]\n",
        "  img_data_aug['height'] = img.shape[0]\n",
        "\n",
        "  return img_data_aug,img\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V12-x9JwHb9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_anchor_gt(all_img_data, C, img_len_calc_function,mode='train'):\n",
        "  \"\"\"\n",
        "  To get ground truth anchors as Y (labels)\n",
        "  \"\"\"\n",
        "  while True:\n",
        "\n",
        "    for img_data in all_img_data:\n",
        "      try:\n",
        "\n",
        "        if mode == 'train':\n",
        "          img_data_aug, x_img = augment(img_data,C,True)\n",
        "        else:\n",
        "          img_data_aug, x_img = augment(img_data,C,False)\n",
        "        \n",
        "        w,h = img_data_aug['width'],img_data_aug['height']\n",
        "\n",
        "        rows,cols, _ = x_img.shape\n",
        "\n",
        "        assert cols == w\n",
        "        assert rows == h\n",
        "\n",
        "        re_w , re_h = get_new_img_size(w,h,C.im_size)\n",
        "\n",
        "        x_img = cv2.resize(x_img,(re_w,re_h),interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "        debug_img = x_img.copy()\n",
        "\n",
        "        try:\n",
        "          y_rpn_cls, y_rpn_regr, num_pos = calc_rpn(C,img_data_aug,w,h,re_w,re_h,\n",
        "                                                    img_length_calc_function)\n",
        "        except:\n",
        "          continue\n",
        "        \n",
        "        x_img = x_img[:,:,(2,1,0)]\n",
        "\n",
        "        x_img = x_img.astype(np.float32)\n",
        "        x_img[:,:,0] -= C.img_channel_mean[0]\n",
        "        x_img[:,:,1] -= C.img_channel_mean[1]\n",
        "        x_img[:,:,2] -= C.img_channel_mean[2]\n",
        "\n",
        "        x_img /= C.img_scaling_factor\n",
        "\n",
        "        x_img = np.transpose(x_img,(0,2,3,1))\n",
        "        x_img = np.expand_dims(x_img,axis = 0)\n",
        "        y_rpn_regr[:, y_rpn_regr.shape[1]//2:, :, :] *= C.std_scaling\n",
        "        x_img = np.transpose(x_img,(0,2,3,1))\n",
        "        y_rpn_cls = np.transpose(y_rpn_cls,(0,2,3,1))\n",
        "        y_rpn_regr = np.transpose(y_rpn_regr,(0,2,3,1))\n",
        "\n",
        "        yield np.copy(x_img), [np.copy(y_rpn_cls),np.copy(y_rpn_regr)], img_data_aug,debug_img,num_pos\n",
        "      \n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "        continue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmJYsqW_IwYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lambda_rpn_regr = 1.0\n",
        "lambda_rpn_class = 1.0\n",
        "lambda_cls_regr = 1.0\n",
        "lambda_cls_class = 1.0\n",
        "\n",
        "epsilon = 1e-4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRRhZ_bVJeVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rpn_loss_regr(num_anchors):\n",
        "  def rpn_loss_regr_fixed_num(y_true, y_pred):\n",
        "    x = y_true[:,:,:,4*num_anchors:] - y_pred\n",
        "    \n",
        "    x_abs = K.abs(x)\n",
        "    x_bool = K.cast(K.less_equal(x_abs,1.0),tf.float32)\n",
        "\n",
        "    return lambda_rpn_regr*K.sum(\n",
        "        y_true[:,:,:,4*num_anchors:] * (x_bool * (0.5 * x * x) + (1 - x_bool) * (x_abs - 0.5))\n",
        "        ) / K.sum(epsilon + y_true[:,:,:,:4*num_anchors])\n",
        "  \n",
        "  return rpn_loss_regr_fixed_num\n",
        "\n",
        "def rpn_loss_cls(num_anchors):\n",
        "  def rpn_loss_cls_fixed_num(y_true, y_pred):\n",
        "    return lambda_rpn_class * K.sum(y_true[:,:,:,:num_anchors] * K.binary_crossentropy(y_pred[:,:,:,:],\n",
        "                                                                                       y_true[:,:,:,num_anchors:])\n",
        "    ) / K.sum(epsilon + y_true[:,:,:,:num_anchors])\n",
        "  return rpn_loss_cls_fixed_num\n",
        "\n",
        "def class_loss_regr(num_classes):\n",
        "  ##TODO\n",
        "  def class_loss_regr_fixed_num(y_true,y_pred):\n",
        "\n",
        "    x = y_true[:,:,4*num_classes:] - y_pred\n",
        "    x_abs = K.abs(x)\n",
        "    x_bool = K.cast(K.less_equal(x_abs,1.0),'float_32')\n",
        "    return lambda_cls_regr*K.sum(y_true[:,:,:4*num_classes]*(x_bool*(0.5*x*x)+(1-x_bool)*(x_abs-0.5)))/K.sum(epsilon+y_true[:,:,:,4*num_classes])\n",
        "  return class_loss_regr_fixed_num\n",
        "\n",
        "def class_loss_cls(y_true,y_pred):\n",
        "  return lambda_cls_class*K.mean(categorical_crossentropy(\n",
        "      y_true[0,:,:],Y_pred[0,:,:]\n",
        "  ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-irY76EE3d0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def non_max_supression_fast(boxes,probs,overlap_thresh=0.9,max_boxes = 300):\n",
        "  if len(boxes) == 0:\n",
        "    return []\n",
        "  \n",
        "  x1 = boxes[:,0]\n",
        "  y1 = boxes[:,1]\n",
        "  x2 = boxes[:,3]\n",
        "  y2 = boxes[:,4]\n",
        "\n",
        "  np.testing.assert_array_less(x1,x2)\n",
        "  np.testing.assert_array_less(y1,y2)\n",
        "\n",
        "  if boxes.dtype.kind == 'i':\n",
        "    boxes = boxes.astype(\"float\")\n",
        "  \n",
        "  pick = []\n",
        "\n",
        "  area = (x2-x1)*(y2-y1)\n",
        "\n",
        "  idxs = np.argsort(probs)\n",
        "\n",
        "  while len(idxs) > 0:\n",
        "    last = len(idxs) - 1\n",
        "    i = idxs[last]\n",
        "    pick.append(i)\n",
        "\n",
        "    xx1_int = np.maximum(x1[i],x1[idxs[:last]])\n",
        "    yy1_int = np.maximum(y1[i],y1[idxs[:last]])\n",
        "    xx2_int = np.minimum(x2[i],x2[idxs[:last]])\n",
        "    yy2_int = np.minimum(y2[i],y2[idxs[:last]])\n",
        "\n",
        "    ww_int = np.maximum(0,xx2_int-xx1_int)\n",
        "    hh_int = np.maximum(0,yy2_int-yy1_int)\n",
        "\n",
        "    area_int = ww_int*hh_int\n",
        "    area_union = area[i] + area[idxs[:last]] - area_int\n",
        "\n",
        "    overlap = area_int/(area_union+1e-6)\n",
        "\n",
        "    idxs = np.delete(idxs,np.concatenate(([last],\n",
        "                                          np.where(overlap>overlap_thresh)[0])))\n",
        "    \n",
        "    if len(pick)>=max_boxes:\n",
        "      break\n",
        "  \n",
        "  boxes = boxes[pick].astype(\"int\")\n",
        "  probs = probs[pick]\n",
        "\n",
        "  return boxes,probs\n",
        "\n",
        "def apply_regr_np(X,T):\n",
        "  \n",
        "  try:\n",
        "    x = X[0,:,:]\n",
        "    y = X[1,:,:]\n",
        "    w = X[2,:,:]\n",
        "    h = X[3,:,:]\n",
        "\n",
        "    tx = T[0,:,:]\n",
        "    ty = T[1,:,:]\n",
        "    tw = T[2,:,:]\n",
        "    th = T[3,:,:]\n",
        "\n",
        "    cx = x + w/2\n",
        "    cy = y + h/2\n",
        "    cx1 = tx*w + cx\n",
        "    cy1 = ty*h + cy\n",
        "\n",
        "    w1 = np.exp(tw.astype(np.float64))*w\n",
        "    h1 = np.exp(th.astype(np.float64))*h\n",
        "    x1 = cx1-w1/2\n",
        "    y1 = cy1-h1/2\n",
        "\n",
        "    x1 = np.round(x1)\n",
        "    y1 = np.round(y1)\n",
        "    w1 = np.round(w1)\n",
        "    h1 = np.round(h1)\n",
        "\n",
        "    return np.stack([x1,y1,w1,h1])\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    return X\n",
        "\n",
        "def apply_regr(x,y,w,h,tx,ty,tw,th):\n",
        "  try:\n",
        "    cx = x + w/2\n",
        "    cy = y + h/2\n",
        "    cx1 = tx*w + cx\n",
        "    cx2 = ty*h + cy\n",
        "    w1 = math.exp(tw) + w\n",
        "    h1 = math.exp(th) + h\n",
        "    x1 = cx1 - w1/2\n",
        "    y1 = cy1 - h1/2\n",
        "    x1 = int(round(x1))\n",
        "    y1 = int(round(y1))\n",
        "    w1 = int(round(w1))\n",
        "    h1 = int(round(h1))\n",
        "\n",
        "    return x1,y1,w1,h1\n",
        "  \n",
        "  except ValueError:\n",
        "    return x,y,w,h\n",
        "  except OverflowError:\n",
        "    return x,y,w,h\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    return x,y,w,h\n",
        "\n",
        "def calc_iou(R,img_data,C,class_mapping):\n",
        "  \n",
        "  bboxes = img_data['bboxes']\n",
        "  (w,h) = (img_data['width'],img_data['height'])\n",
        "  (r_w,r_h) = get_new_img_size(w,h,C.im_size)\n",
        "  gta = np.zeros((len(bboxes),4))\n",
        "  \n",
        "  for bbox_num, bbox in enumerate(bboxes):\n",
        "    gta[bbox_num,0] = int(round(bbox['x1']*(resized_width/float(w))/C.rpn_stride))\n",
        "    gta[bbox_num,1] = int(round(bbox['x2']*(resized_width/float(w))/C.rpn_stride))\n",
        "    gta[bbox_num,2] = int(round(bbox['y1']*(resized_height/float(h))/C.rpn_stride))\n",
        "    gta[bbox_num,3] = int(round(bbox['y2']*(resized_height/float(h))/C.rpn_stride))\n",
        "  \n",
        "  x_roi = []\n",
        "  y_class_num = []\n",
        "  y_class_regr_coords = []\n",
        "  y_class_regr_label = []\n",
        "  IoUs = []\n",
        "\n",
        "  for ix in range(R.shape[0]):\n",
        "    (x1,y1,x2,y2) = R[ix,:]\n",
        "    x1 = int(round(x1))\n",
        "    x2 = int(round(x2))\n",
        "    y1 = int(round(y1))\n",
        "    y2 = int(round(y2))\n",
        "\n",
        "    best_iou = 0.0\n",
        "    best_bbox = -1\n",
        "\n",
        "    for bbox_num in range(len(bboxes)):\n",
        "      curr_iou = iou([gta[bbox_num,0],gta[bbox_num,2],gta[bbox_num,1],gta[bbox_num,3]],\n",
        "                     [x1,y1,x2,y2])\n",
        "      if curr_iou>best_iou:\n",
        "        best_iou = curr_iou\n",
        "        best_bbox = bbox_num\n",
        "    if best_iou < C.classifier_min_overlap:\n",
        "      continue\n",
        "    else:\n",
        "      w = x2 - x1\n",
        "      h = y2 - y1\n",
        "      x_roi.append([x1,y1,w,h])\n",
        "      IoUs.append(best_iou)\n",
        "\n",
        "      if C.classifier_min_overlap <= best_iou <C.classifier_max_overlap :\n",
        "        cls_name = 'bg'\n",
        "      elif C.classifier_max_overlap<=best_iou:\n",
        "        cls_name = bboxes[best_bbox]['class']\n",
        "        cxg = (gta[best_bbox,0]+gta[best_bbox,1])/2.0\n",
        "        cyg = (gta[best_bbox,2]+gta[best_bbox,3])/2.0\n",
        "\n",
        "        cx = x1 + w/2.0\n",
        "        cy = y1 + h/2.0\n",
        "\n",
        "        tx = (cxg-cx)/float(w)\n",
        "        ty = (cyg-cy)/float(h)\n",
        "\n",
        "        tw = np.log((gta[best_bbox,1] - gta[best_bbox,0])/float(w))\n",
        "        th = np.log((gta[best_bbox,3] - gta[best_bbox,2])/float(h))\n",
        "\n",
        "      else:\n",
        "        print('roi = {}'.format(best_iou))\n",
        "        raise RuntimeError\n",
        "    \n",
        "    class_num = class_mapping[cls_name]\n",
        "    class_label = len(class_mapping) * [0]\n",
        "    class_label[class_name] = 1\n",
        "    y_class_num.append(copy.deepcopy(class_label))\n",
        "    coords = [0]*4*(len(class_mapping) - 1)\n",
        "    labels = [0]*4*(len(class_mapping) - 1)\n",
        "\n",
        "    if cls_name != 'bg':\n",
        "      label_pos = 4*class_num\n",
        "      sx,sy,sw,sh = C.classifier_regr_std\n",
        "      coords[label_pos:4+label_pos] = [sx*tx,sy*ty,sw*tw,sh*th]\n",
        "\n",
        "      labels[label_pos:4+label_pos] = [1,1,1,1]\n",
        "      y_class_regr_coords.append(copy.deepcopy(coords))\n",
        "      y_class_regr_label.append(copy.deepcopy(labels))\n",
        "  \n",
        "  if len(x_roi) == 0:\n",
        "    return None,None,None,None\n",
        "  \n",
        "  X = np.array(x_roi)\n",
        "  Y1 = np.array(y_class_name)\n",
        "  Y2 = np.concatenate([np.array(y_class_regr_label),np.array(y_class_regr_coords)],axis = 1)\n",
        "\n",
        "  return np.expand_dims(X,axis = 0),np.expand_dims(Y1,axis=0),np.expand_dims(Y2,axis=0),IoUs \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4E7mYNxPsbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rpn_to_roi(rpn_layer,regr_layer,C,dim_ordering,use_regr = True,max_boxes=300,overlap_thresh=0.9):\n",
        "  regr_layer = regr_layer / C.std_scaling\n",
        "\n",
        "  anchor_sizes = C.anchor_box_scales\n",
        "  anchor_ratios = C.anchor_box_ratios\n",
        "\n",
        "  assert rpn_layer.shape[0] == 1\n",
        "\n",
        "  r,c = rpn_layer.shape[1:3]\n",
        "\n",
        "  curr_layer = 0\n",
        "\n",
        "  A = np.zeros((4,rpn_layer.shape[1],rpn_layer.shape[2]),rpn_layer.shape[3])\n",
        "\n",
        "  for anchor_size in anchor_sizes:\n",
        "\n",
        "    for anchor_ratio in anchor_ratios:\n",
        "\n",
        "      anchor_x = (anchor_size * anchor_ratio[0])/C.rpn_stride\n",
        "      anchor_y = (anchor_size * anchor_ratio[1])/C.rpn_stride\n",
        "\n",
        "      regr = regr_layer[0,:,:,4*curr_layer:4*curr_layer+4]\n",
        "      regr = np.transpose(regr,(2,0,1))\n",
        "\n",
        "      X,Y = np.meshgrid(np.arange(c),np.arange(r))\n",
        "\n",
        "      A[0,:,:,curr_layer] = X - anchor_x/2\n",
        "      A[1,:,:,curr_layer] = Y - anchor_x/2\n",
        "      A[2,:,:,curr_layer] = anchor_x\n",
        "      A[3,:,:,curr_layer] = anchor_y\n",
        "\n",
        "      if use_regr :\n",
        "        A[:,:,:,curr_layer] = apply_regr_np(A[:,:,:,curr_layer],regr)\n",
        "\n",
        "        A[2,:,:,curr_layer] = np.maximum(1,A[2,:,:,curr_layer])\n",
        "        A[3,:,:,curr_layer] = np.maximum(1,A[2,:,:,curr_layer])\n",
        "        \n",
        "        #convert x,y,w,h to x1,y1,x2,y2\n",
        "\n",
        "        A[2,:,:,curr_layer] += A[0,:,:,curr_layer]\n",
        "\n",
        "        A[3,:,:,curr_layer] += A[1,:,:,curr_layer]\n",
        "\n",
        "        #restrict max and min of coordinates\n",
        "\n",
        "        A[0,:,:,curr_layer] = np.maximum(0,A[0,:,:,curr_layer])\n",
        "        A[1,:,:,curr_layer] = np.maximum(0,A[1,:,:,curr_layer])\n",
        "        A[2,:,:,curr_layer] = np.minimum(c-1,A[2,:,:,curr_layer])\n",
        "        A[3,:,:,curr_layer] = np.minimum(r-1,A[3,:,:,curr_layer])\n",
        "\n",
        "        curr_layer += 1\n",
        "    \n",
        "    all_boxes = np.reshape(A.transpose((0,3,1,2)),(4,-1)).transpose((1,0))\n",
        "\n",
        "    all_probs = rpn_layer.transpose((0,3,1,2)).reshape((-1))\n",
        "\n",
        "    x1 = all_boxes[:,0]\n",
        "    y1 = all_boxes[:,1]\n",
        "    x2 = all_boxes[:,2]\n",
        "    y2 = all_boxes[:,3]\n",
        "\n",
        "    idxs = np.where((x1-x2>=0)|(y1-y2>=0))\n",
        "\n",
        "    all_boxes = np.delete(all_boxes,idxs,0)\n",
        "    all_probs = np.delete(all_probs,idxs,0)\n",
        "\n",
        "    #apply non max suppresion to all the boxes\n",
        "\n",
        "    result = non_max_supression_fast(all_boxes,\n",
        "                                     all_probs,\n",
        "                                     overlap_thresh=overlap_thresh,\n",
        "                                     max_boxes = maxboxes)[0]\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FTkHTj_f7eT",
        "colab_type": "text"
      },
      "source": [
        "Start Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CfsfLz3f60w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_path = 'drive/My Drive/Dataset'\n",
        "\n",
        "train_path = 'drive/My Drive/Dataset/annotation.txt'\n",
        "\n",
        "#number of Region of Interests to process at once\n",
        "num_rois = 4\n",
        "\n",
        "#Augmenting the image flags\n",
        "horizontal_flips = True\n",
        "vertical_flips = True\n",
        "rot_90 = True\n",
        "\n",
        "output_weight_path = os.path.join(base_path,'model/model_fcrnn_vgg.h5')\n",
        "\n",
        "record_path = os.path.join(base_path,'model/record.csv') # to store metrics\n",
        "\n",
        "base_weight_path = os.path.join(base_path,'model/vgg16_weights_tf_dim_ordering_tf_kernels.h5')\n",
        "\n",
        "config_output_filename = os.path.join(base_path,'model/model_vgg_config.pickle')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8sXfX_1jIMy",
        "colab_type": "text"
      },
      "source": [
        "<h2> Create a config for our training</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-7Jr7IxjG1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "C = Config()\n",
        "\n",
        "C.use_horizontal_flips = horizontal_flips\n",
        "C.use_vertical_flips = vertical_flips\n",
        "C.rot_90 = rot_90\n",
        "\n",
        "C.record_path = record_path\n",
        "C.model_path = output_weight_path\n",
        "C.num_rois = num_rois\n",
        "\n",
        "C.base_net_weights = base_weight_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQlpMMuXjwdu",
        "colab_type": "code",
        "outputId": "6ecd262d-98f5-4c1b-a129-c20a9d3474bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "st = time.time()\n",
        "train_imgs,classes_count, class_mapping = get_data(train_path)\n",
        "print()\n",
        "print('Spend %0.2f mins to load the data' % ((time.time()-st)/60) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsing annotation files....\n",
            "idx=2755\n",
            "Spend 17.29 mins to load the data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw2PbG-jsVXM",
        "colab_type": "code",
        "outputId": "0cb5e6e6-5257-4ba1-fee3-aa5e0ddbd0c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "if 'bg' not in classes_count:\n",
        "  classes_count['bg'] = 0\n",
        "  class_mapping['bg'] = len(class_mapping)\n",
        "\n",
        "C.class_mapping = class_mapping\n",
        "print('Training images per class:')\n",
        "pprint.pprint(classes_count)\n",
        "print(\"Num classes (including bg) = {}\".format(len(classes_count)))\n",
        "print(class_mapping)\n",
        "\n",
        "with open(config_output_filename,'wb') as config_f:\n",
        "  pickle.dump(C,config_f)\n",
        "  print(\"Config has been written to {}, and can be loaded when testing to ensure correct results\".format(config_output_filename))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training images per class:\n",
            "{'Car': 906, 'Person': 1428, 'Phone': 421, 'bg': 0}\n",
            "Num classes (including bg) = 4\n",
            "{'Car': 0, 'Person': 1, 'Phone': 2, 'bg': 3}\n",
            "Config has been written to drive/My Drive/Dataset/model/model_vgg_config.pickle, and can be loaded when testing to ensure correct results\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U91fe6cauTCe",
        "colab_type": "code",
        "outputId": "6af7ccbe-1336-4e39-9bb8-fae2b5da1c7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "random.seed(1)\n",
        "random.shuffle(train_imgs)\n",
        "\n",
        "print(\"Num train samples (images) {}\".format(len(train_imgs)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num train samples (images) 878\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXoUwwFkupHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_gen_train = get_anchor_gt(train_imgs,\n",
        "                               C,\n",
        "                               get_image_output_length,\n",
        "                               mode='train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cceHzoY0yMSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, Y, image_data, debug_img, debug_num_pos = next(data_gen_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiXFMgQDynDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Original image: height=%d width=%d\"%(image_data['height'],\n",
        "                                            image_data['width']))\n",
        "print('Resized image: height=%d width=%d C.im_size=%d'%(X.shape[1],X.shape[2],C.im_size))\n",
        "\n",
        "print('Feature map size: height=%d width=%d C.rpn_stride=%d'%(Y[0].shape[1],Y[0].shape[2],C.rpn_stride))\n",
        "\n",
        "print(X.shape)\n",
        "\n",
        "print(str(len(Y))+\" includes 'y_rpn_cls' and 'y_rpn_regr'\")\n",
        "print('shape of y_rpn_cls {}'.format(Y[0].shape))\n",
        "print('shape of y_rpn_regr {}'.format(Y[1].shape))\n",
        "\n",
        "print(img_data)\n",
        "\n",
        "print('Number of positive anchors for this image:%d'%(debug_num_pos))\n",
        "\n",
        "if debug_num_pos==0:\n",
        "  gt_x1, gt_x2 = image_data['bboxes'][0]['x1']*(X.shape[2]/image_data['height']), image_data['bboxes'][0]['x2']*(X.shape[2]/image_data['height'])\n",
        "\n",
        "  gt_y1, gt_y2 = image_data['bboxes'][0]['y1']*(X.shape[1]/image_data['width']),image_data['bboxes'][0]['y2']*(X.shape[1]/image_data['width'])\n",
        "\n",
        "  gt_x1, gt_x2, gt_y1, gt_y2 = int(gt_x1),int(gt_x2),int(gt_y1),int(gt_y2)\n",
        "\n",
        "\n",
        "  img = debug_img.copy()\n",
        "  img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "  color = (0,255,0)\n",
        "  cv2.putText(img,'gt_bbox',(gt_x1,gt_x2-5), cv2.FONT_HERSHEY_DUPLEX, 0.7,color,1)\n",
        "  cv2.rectangle(img,(gt_x1,gt_y1),(gt_x2,gt_y2),color,2)\n",
        "  cv2.circle(img,(int((gt_x1+gt_x2)/2),int((gt_y1+gt_y2)/2)),3,color,-1)\n",
        "\n",
        "  plt.grid()\n",
        "  plt.imshow()\n",
        "  plt.show()\n",
        "else:\n",
        "  cls = Y[0][0]\n",
        "  pos_cls = np.where(cls==1)\n",
        "  print(pos_cls)\n",
        "  regr = Y[1][0]\n",
        "  pos_regr = np.where(regr==1)\n",
        "  print(pos_regr)\n",
        "  print('y_rpn_cls for possible pos anchor: {}'.format(cls[pos_cls[0][0],pos_cls[1][0],:]))\n",
        "  print('y_rpn_regr for positive anchor: {}'.format(regr[pos_regr[0][0],pos_regr[1][0],:]))\n",
        "  \n",
        "  gt_x1, gt_x2 = image_data['bboxes'][0]['x1']*(X.shape[2/image_data['width']]),image_data['bboxes'][0]['x2']*(X.shape[2/image_data['height']])\n",
        "  gt_y1, gt_y2 = image_data['bboxes'][0]['y1']*(X.shape[1]/image_data['width']),image_data['bboxes'][1]['y2']*(X.shape[2/iamge_data['width']])\n",
        "  gt_x1, gt_x2,gt_y1, gt_y2 = int(gt_x1),int(gt_x2),int(gt_y1),int(gt_y2)\n",
        "\n",
        "  img = debug_img.copy()\n",
        "  img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  color = (0,255,0)\n",
        "\n",
        "  cv2.rectangle(img,(gt_x2,gt_y2),(gt_x1,gt_y1),color,2)\n",
        "  cv2.circle(img,(int((gt_x1+gt_x2)/2),int((gt_y1+gt_y2)/2)),3,color,-1)\n",
        "\n",
        "  #Add label\n",
        "  textLabel = 'gt bbox'\n",
        "  (retval,baseLine) = cv2.getTextSize(testLabel,cv2.FONT_HERSHEY_COMPLEX,0.5,1)\n",
        "  textOrg = (gt_x1,gt_y1+5)\n",
        "  cv2.rectangle(img,(textOrg[0] - 5, textOrg[1]+baseLine - 5), (testOrg[0]+retval[0]+5,textOrg[1]-retval[1]-5),(0,0,0),2)\n",
        "  cv2.rectangle(img,(textOrg[0] - 5, textOrg[1]+baseLine - 5), (testOrg[0]+retval[0]+5,textOrg[1]-retval[1]-5),(255,255,255),-1)\n",
        "  cv2.putText(img,textLabel,textOrg,cv2.FONT_HERSHEY_DUPLEX,0.5,(0,0,0),1)\n",
        "\n",
        "  #Draw positive anchors according to the y_rpn_regr\n",
        "  for i in range(debug_num_pos):\n",
        "    color = (100+i*(155/4),0,100+i*(155/4))\n",
        "\n",
        "    idx = pos_regr[2][i*4]/4\n",
        "    anchor_size = C.anchor_box_scales[int(idx/3)]\n",
        "    anchor_ratio = C.anchor_box_ratio[2-int((idx+1)%3)]\n",
        "\n",
        "    center = (pos_regr[1][i*4]*C.rpn_stride,pos_regr[0][i*4]*C.rpn_stride)\n",
        "\n",
        "    print('Center position of positive anchor: ',center)\n",
        "\n",
        "    cv2.circle(img,center,3,color,-1)\n",
        "    anc_w,anc_h = anchor_size*anchor_ratio[0], anchor_size*anchor_ratio[1]\n",
        "    cv2.rectangle(img,(center[0]-int(anc_w/2),center[1]-int(anc_h/2)),(center[0]+int(anc_w/2),center[1]+int(anc_h/2)),color,2)\n",
        "\n",
        "  print('Green boxes are GT, others are positive anchors')\n",
        "  plt.figure(figsize=(8,8))\n",
        "  plt.grid()\n",
        "  plt.imshow(img) \n",
        "  plt.show() \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aztnMQmdQISl",
        "colab_type": "text"
      },
      "source": [
        "Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDWONMrCP_RW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape_img = (None,None,3)\n",
        "img_input = Input(shape = input_shape_img)\n",
        "roi_input = Input(shape = (None,4))\n",
        "\n",
        "#define the base network (VGG here, can be Resnet50)\n",
        "\n",
        "shared_layers = nn_base(img_input,trainable = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IViQh5V-RTn0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_anchors = len(C.anchor_box_scales) * len(C.anchor_box_ratios)\n",
        "rpn = rpn_layer(shared_layers,num_anchors)\n",
        "\n",
        "classifier = classifier_layer(shared_layers,roi_input,C.num_rois,nb_classes = len(classes_count))\n",
        "model_rpn = Model(img_input,rpn[:2])\n",
        "model_classifier = Model([img_input,roi_input],classifier)\n",
        "#model holding RPN and classifier\n",
        "model_all = Model([img_input,roi_input],rpn[:2]+classifier)\n",
        "\n",
        "if not os.path.isfile(C.model_path):\n",
        "  try:\n",
        "    print('This is the first time you are training')\n",
        "    print('loading weights from {}'.format(C.base_net_weights))\n",
        "    model_rpn.load_weights(C.base_net_weights,by_name = True)\n",
        "    model_classifier.load_weights(C.base_net_weights,by_name = True)\n",
        "  except:\n",
        "    print('Unable to load weight')\n",
        "else:\n",
        "  print('Continuing Training based on previous trained model')\n",
        "  print('Loading weights from {}'.format(C.model_path))\n",
        "  model_rpn.load_weights(C.model_path,by_name= True)\n",
        "  model_classifier.load_weights(C.model_path,by_name = True)\n",
        "  record_df = pd.read_csv(record_path)\n",
        "  r_mean_overlapping_bboxes = record_df['mean_overlapping_bboxes']\n",
        "  r_class_acc = record_df['class_acc']\n",
        "  r_loss_rpn_cls = record_df['loss_rpn_cls']\n",
        "  r_loss_rpn_regr = record_df['loss_rpn_regr']\n",
        "  r_loss_class_cls = record_df['loss_class_cls']\n",
        "  r_loss_class_regr = record_df['loss_class_regr']\n",
        "  r_curr_loss = record_df ['curr_loss']\n",
        "  r_elapsed_time = record_df['elapsed_time']\n",
        "  r_mAP = record_df['mAP']\n",
        "\n",
        "  print('Already train batches: ', len(record_df))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ3rw3DbXPEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = Adam(lr=1e-5)\n",
        "optimizer_classifier = Adam(lr=1e-5)\n",
        "model_rpn.compile(optimizer = optimizer, loss = [rpn_loss_cls(num_anchors),rpn_loss_regr(num_anchors)])\n",
        "model_classifier.compile(optimizer = optimizer_classifier,loss = [class_loss_cls,class_loss_regr(len(classes_count)-1)],\n",
        "                         metrics = {'dense_class_{}'.format(len(classes_count)):'accuracy'})\n",
        "model_all.compile(optimizer = 'sgd',loss='name')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKBCwMHYZm_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training Settings\n",
        "total_epochs = len(record_df)\n",
        "r_epochs = len(record_df)\n",
        "\n",
        "epoch_length = 1000\n",
        "num_epochs = 40\n",
        "iter_num = 0\n",
        "\n",
        "total_epochs += num_epochs\n",
        "losses = np.zeros((epoch_length,5))\n",
        "rpn_accuracy_rpn_monitor = []\n",
        "rpn_accuracy_rpn_epoch = []\n",
        "\n",
        "if len(record_df) == 0:\n",
        "  best_loss = np.Inf\n",
        "else:\n",
        "  best_loss = np.min(r_curr_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1A-Q-OSfHHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(record_df))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDUJEm-LfSXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_time = time.time()\n",
        "\n",
        "for epoch_num in range(num_epochs):\n",
        "\n",
        "  progbar = generic_utils.Progbar(epoch_length)\n",
        "  print('Epoch {}/{}'.format(r_epochs + 1,total_epochs))\n",
        "\n",
        "  r_epochs += 1\n",
        "  while True:\n",
        "    try:\n",
        "      if len(rpn_accuracy_rpn_monitor) == epoch_length and C.verbose:\n",
        "        mean_overlapping_bboxes = float(sum(rpn_accuracy_rpn_monitor))/len(rpn_accuracy_rpn_monitor)\n",
        "        rpn_accuracy_rpn_monitor = []\n",
        "\n",
        "        if mean_overlapping_bboxes == 0:\n",
        "          print(\"RPN not producing any bounding boxes that overlap any GT boxes.\")\n",
        "      X,Y,img_data,debug_img,debug_num_pos = next(data_gen_train)\n",
        "\n",
        "      loss_rpn = model_rpn.train_on_batch(X,Y)\n",
        "      P_rpn = model_rpn.predict_on_batch(X)\n",
        "\n",
        "      #R:bboxes shape = 300,4\n",
        "      R = rpn_to_roi(P_rpn[0],P_rpn[1],C,K.image_dim_ordering(),\n",
        "                     use_regr = True,\n",
        "                     overlap_thresh = 0.7,\n",
        "                     max_boxes = 300)\n",
        "      X2,Y1,Y2,Ious = calc_iou(R,img_data,C,class_mapping)\n",
        "\n",
        "      if X2 is None:\n",
        "        rpn_accuracy_rpn_monitor.append(0)\n",
        "        rpn_accuracy_for_epoch.append(0)\n",
        "        continue\n",
        "\n",
        "      #pos anchors and neg anchors      \n",
        "      neg_samples = np.where(Y1[0,:,-1] == 1)\n",
        "      pos_samples = np.where(Y1[0,:,-1] == 0)\n",
        "\n",
        "      if len(neg_samples) > 0:\n",
        "        neg_samples = neg_samples[0]\n",
        "      else:\n",
        "        neg_samples = []\n",
        "\n",
        "      if len(pos_samples) > 0:\n",
        "        pos_samples = pos_samples[0]\n",
        "      else:\n",
        "        pos_samples = []\n",
        "\n",
        "      rpn_accuracy_rpn_monitor.append(len(pos_samples))\n",
        "      rpn_accuracy_for_epoch.append(len(pos_samples))\n",
        "\n",
        "      if C.num_rois > 1:\n",
        "        if len(pos_samples) < C.num_rois//2:\n",
        "          select_pos_samples = pos_samples_tolist()\n",
        "        else:\n",
        "          select_pos_samples = np.random.choice(pos_samples,C.num_rois//2,replace=False).tolist()\n",
        "\n",
        "          try:\n",
        "            select_neg_samples = np.random.choice(neg_samples,C.num_rois - len(selected_pos_samples),replace = False).tolist()\n",
        "          except:\n",
        "            selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=True).tolist()\n",
        "\n",
        "            #save all samples pos and neg\n",
        "            sel_samples = selected_pos_samples + selected_neg_samples\n",
        "      else:\n",
        "        #if num_rois is 1 we can take only one and we take any random\n",
        "        selected_pos_samples = pos_samples.tolist()\n",
        "        selected_neg_samples = neg_samples.tolist()\n",
        "\n",
        "        if np.random.randint(0,2):\n",
        "          sel_samples = random.choice(neg_samples)\n",
        "        else:\n",
        "          loss_class = model_classifier.train_on_batch([X,X2[:,sel_samples,:]],[Y1[:,sel_samples,:],Y2[:,sel_samples,:]])\n",
        "          losses[iter_num,0] = loss_rpn[1]\n",
        "          losses[iter_num,1] = loss_rpn[2]\n",
        "\n",
        "          losses[iter_num,2] = loss_class[1]\n",
        "          losses[iter_num,3] = loss_class[2]\n",
        "          losses[iter_num,4] = loss_class[3]\n",
        "\n",
        "          iter_num += 1\n",
        "\n",
        "          progbar.update(iter_num, [('rpn_cls', np.mean(losses[:iter_num, 0])), ('rpn_regr', np.mean(losses[:iter_num, 1])),\n",
        "                                    ('final_cls', np.mean(losses[:iter_num, 2])), ('final_regr', np.mean(losses[:iter_num, 3]))])\n",
        "          if iter_num == epoch_length:\n",
        "            loss_rpn_cls = np.mean(losses[:,0])\n",
        "            loss_rpn_regr = np.mean(losses[:,1])\n",
        "            loss_class_cls = np.mean(losses[:,2])\n",
        "            loss_class_regr = np.mean(losses[:,3])\n",
        "            class_acc = np.mean(losses[:,4])\n",
        "\n",
        "            mean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch))/len(rpn_accuracy_for_epoch)\n",
        "\n",
        "            rpn_accuracy_for_epoch = []\n",
        "\n",
        "            if C.verbose:\n",
        "              print('Mean number of bounding boxes from RPN overlapping ground truth boxes: {}'.format(mean_overlapping_bboxes))\n",
        "              print('Classifier accuracy for bounding boxes from RPN: {}'.format(class_acc))\n",
        "              print('Loss RPN classifier: {}'.format(loss_rpn_cls))\n",
        "              print('Loss RPN regression: {}'.format(loss_rpn_regr))\n",
        "              print('Loss Detector classifier: {}'.format(loss_class_cls))\n",
        "              print('Loss Detector regression: {}'.format(loss_class_regr))\n",
        "              print('Total loss: {}'.format(loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr))\n",
        "              print('Elapsed time: {}'.format(time.time() - start_time))\n",
        "              elapsed_time = (time.time()-start_time)/60\n",
        "\n",
        "            curr_loss = loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr\n",
        "            iter_num = 0\n",
        "            start_time = time.time()\n",
        "            if curr_loss < best_loss:\n",
        "              if C.verbose:\n",
        "                print('Total loss decreased from {} to {}, saving weights'.format(best_loss,curr_loss))\n",
        "              best_loss = curr_loss\n",
        "              model_all.save_weights(C.model_path)\n",
        "\n",
        "            new_row = {'mean_overlapping_bboxes':round(mean_overlapping_bboxes, 3), \n",
        "                        'class_acc':round(class_acc, 3), \n",
        "                        'loss_rpn_cls':round(loss_rpn_cls, 3), \n",
        "                        'loss_rpn_regr':round(loss_rpn_regr, 3), \n",
        "                        'loss_class_cls':round(loss_class_cls, 3), \n",
        "                        'loss_class_regr':round(loss_class_regr, 3), \n",
        "                        'curr_loss':round(curr_loss, 3), \n",
        "                        'elapsed_time':round(elapsed_time, 3), \n",
        "                        'mAP': 0}\n",
        "\n",
        "            record_df = record_df.append(new_row, ignore_index=True)\n",
        "            record_df.to_csv(record_path, index=0)\n",
        "            break\n",
        "\n",
        "    except Exception as e:\n",
        "      print('Exception: {}'.format(e))\n",
        "      continue\n",
        "\n",
        "  print('Training complete, exiting.')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}