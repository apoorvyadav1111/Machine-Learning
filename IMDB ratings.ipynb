{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras.layers as layers\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not all films made in 1931 are this creaky, an...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BIG FAT LIAR, in my opinion, is an absolutely ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hitchcock made at least 11 films about the ord...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film sold for one-dollar at Wal-Mart on a...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No Holds Barred is that movie that when you we...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  Not all films made in 1931 are this creaky, an...        1.0\n",
       "1  BIG FAT LIAR, in my opinion, is an absolutely ...        1.0\n",
       "2  Hitchcock made at least 11 films about the ord...        1.0\n",
       "3  This film sold for one-dollar at Wal-Mart on a...        0.0\n",
       "4  No Holds Barred is that movie that when you we...        1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df = pd.read_csv(\"movie-ratings.csv\",encoding='utf-8')\n",
    "df.head()\n",
    "#df[\"review\"] = df[\"review\"].map(re.sub(\"[^a-zA-Z0-9 ]\",\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.loc[:24999,'review'].values\n",
    "y_train = df.loc[:24999,'sentiment'].values\n",
    "X_test = df.loc[25000:,'review'].values\n",
    "y_test = df.loc[25000:,'sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Not all films made in 1931 are this creaky, and the fact that this was \"Best Picture\" must have given even greater impetus to the development of television.<br /><br />Typical of all Ferber novels, it isn\\'t possible to bring the entire story to the screen, to say nothing of developing character. Dix -- so stolid in the first third of the movie -- does an about face, but no one knows why and it makes no sense. And what is there about Dunne that makes makes her so stoical? Edna May Oliver\\'s scenes are priceless, as usual.<br /><br />This film has a role to play in the history of cinema, but it is long and boring.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_obj = Tokenizer()\n",
    "total_reviews = X_train+X_test\n",
    "tokenizer_obj.fit_on_texts(total_reviews)\n",
    "\n",
    "#pad_sequences\n",
    "max_len = max([len(s.split()) for s in total_reviews])\n",
    "\n",
    "#vocab_size\n",
    "vocab_size = len(tokenizer_obj.word_index)+1\n",
    "\n",
    "X_train_tokens = tokenizer_obj.texts_to_sequences(X_train)\n",
    "X_test_tokens = tokenizer_obj.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_tokens,maxlen=max_len,padding=\"post\")\n",
    "X_test_pad = pad_sequences(X_test_tokens,maxlen=max_len,padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emd_dim = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size,emd_dim,input_length=max_len))\n",
    "model.add(layers.GRU(units=32,dropout=0.2,recurrent_dropout=0.2))\n",
    "model.add(layers.Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_pad,y_train,batch_size=128,epochs=25,validation_data=(X_test_pad,y_test),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_lines = list()\n",
    "lines = df[\"review\"].values.tolist()\n",
    "\n",
    "table = str.maketrans('','',string.punctuation)\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "for line in lines:\n",
    "    tokens = word_tokenize(line.lower())\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    words = [word for word in stripped if word.isalpha() and word not in stop_words]\n",
    "    review_lines.append(words)\n",
    "len(review_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "emd_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134095"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(sentences = review_lines,\n",
    "                              size=emd_dim,\n",
    "                              window=5,\n",
    "                              workers=4,\n",
    "                              min_count=1)\n",
    "words = list(model.wv.vocab)\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/home/apoorv/Machine-Learning/imdb_wv.txt\"\n",
    "model.wv.save_word2vec_format(filename,binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "emb_index = {}\n",
    "f = open(\"/home/apoorv/Machine-Learning/imdb_wv.txt\",encoding=\"utf-8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.array(values[1:])\n",
    "    emb_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkn = Tokenizer()\n",
    "tkn.fit_on_texts(review_lines)\n",
    "seq = tkn.texts_to_sequences(review_lines)\n",
    "\n",
    "word_index = tkn.word_index\n",
    "review_pad = pad_sequences(seq,maxlen=max_len)\n",
    "sentiment = df[\"sentiment\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   0,   0, ..., 309,  97, 226], dtype=int32), 1.0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_pad[0],sentiment[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = len(word_index)+1\n",
    "emd_matrix = np.zeros((num_words,emd_dim))\n",
    "\n",
    "for word, i  in word_index.items():\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    emd_vector = emb_index.get(word)\n",
    "    if emd_vector is not None:\n",
    "        emd_matrix[i] = emd_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134096"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/apoorv/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/apoorv/anaconda3/envs/tensorflow/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.initializers import Constant\n",
    "\n",
    "# define model\n",
    "\n",
    "model = Sequential()\n",
    "emd_layer = Embedding(num_words,\n",
    "                     emd_dim,\n",
    "                     embeddings_initializer=Constant(emd_matrix),\n",
    "                     input_length=max_len,\n",
    "                     trainable=False)\n",
    "model.add(emd_layer)\n",
    "model.add(GRU(units=32,dropout=0.2,recurrent_dropout=0.2))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss = \"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 2898, 100)         13409600  \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 32)                12768     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 13,422,401\n",
      "Trainable params: 12,801\n",
      "Non-trainable params: 13,409,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_split = 0.2 \n",
    "indices = np.arange(review_pad.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "review_pad = review_pad[indices]\n",
    "sentiment = sentiment[indices]\n",
    "num_val_samples = int(val_split*review_pad.shape[0])\n",
    "\n",
    "X_train_pad = review_pad[:-num_val_samples]\n",
    "y_train = sentiment[:-num_val_samples]\n",
    "\n",
    "X_test_pad = review_pad[-num_val_samples:]\n",
    "y_test  = sentiment[-num_val_samples:]\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/apoorv/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "13696/40000 [=========>....................] - ETA: 7:16 - loss: 0.5560 - acc: 0.7465"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_pad,y_train,batch_size=128, epochs=10,verbose=1,\n",
    "         validation_data=(X_test_pad,y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
